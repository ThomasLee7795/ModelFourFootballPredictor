{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load libraries\n",
    "import pandas\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "from patsy import dmatrices\n",
    "from pandas.plotting import scatter_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn import model_selection\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "dataset = pandas.read_csv('C:/Users/Thoma/OneDrive/Desktop/PredictorFour/FinalData.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#These values do not affect what we are predicting (not even referee in my opinion) so we will delete them\n",
    "del dataset['ID']\n",
    "del dataset['Date']\n",
    "del dataset['Referee']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#These are neither getting predicted or providing prior knowledge\n",
    "del dataset['HTHG']\n",
    "del dataset['HTAG']\n",
    "del dataset['HTR-A']\n",
    "del dataset['HTR-D']\n",
    "del dataset['HTR-H']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#normalisation. Dividing wins by number of games played to make it even for all teams. Can't do 0 divided by 0 so keep the same if less than 1\n",
    "dataset['HHWins'] = np.where(dataset['HHGames'] < 1, dataset['HHWins'], dataset['HHWins']/dataset['HHGames'])\n",
    "dataset['AHWins'] = np.where(dataset['AHGames'] < 1, dataset['AHWins'], dataset['AHWins']/dataset['AHGames'])\n",
    "dataset['HAWins'] = np.where(dataset['HAGames'] < 1, dataset['HAWins'], dataset['HAWins']/dataset['HAGames'])\n",
    "dataset['AAWins'] = np.where(dataset['AAGames'] < 1, dataset['AAWins'], dataset['AAWins']/dataset['AAGames'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Encode the strings as numericals in order for the algorithms to be able to take them\n",
    "#0-Away win, 1- Draw, 2- Home Win\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "lbl_enc = LabelEncoder()\n",
    "lbl_enc.fit(dataset.FTR)\n",
    "dataset.FTR = lbl_enc.transform(dataset.FTR)\n",
    "lbl_enc.fit(dataset.HomeTeam)\n",
    "dataset.HomeTeam = lbl_enc.transform(dataset.HomeTeam)\n",
    "lbl_enc.fit(dataset.AwayTeam)\n",
    "dataset.AwayTeam = lbl_enc.transform(dataset.AwayTeam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HomeTeam</th>\n",
       "      <th>AwayTeam</th>\n",
       "      <th>FTHG</th>\n",
       "      <th>FTAG</th>\n",
       "      <th>HS</th>\n",
       "      <th>AS</th>\n",
       "      <th>HST</th>\n",
       "      <th>AST</th>\n",
       "      <th>HF</th>\n",
       "      <th>AF</th>\n",
       "      <th>...</th>\n",
       "      <th>HHCorners</th>\n",
       "      <th>HAShots</th>\n",
       "      <th>HAShotsTarget</th>\n",
       "      <th>HACorners</th>\n",
       "      <th>AHShots</th>\n",
       "      <th>AHShotsTarget</th>\n",
       "      <th>AHCorners</th>\n",
       "      <th>AAShots</th>\n",
       "      <th>AAShotsTarget</th>\n",
       "      <th>AACorners</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FTR</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>10.927944</td>\n",
       "      <td>8.571178</td>\n",
       "      <td>0.602812</td>\n",
       "      <td>2.233743</td>\n",
       "      <td>12.430580</td>\n",
       "      <td>12.776801</td>\n",
       "      <td>4.797891</td>\n",
       "      <td>6.126538</td>\n",
       "      <td>11.404218</td>\n",
       "      <td>11.611599</td>\n",
       "      <td>...</td>\n",
       "      <td>5.069872</td>\n",
       "      <td>9.603560</td>\n",
       "      <td>4.189039</td>\n",
       "      <td>4.165731</td>\n",
       "      <td>9.853875</td>\n",
       "      <td>4.291985</td>\n",
       "      <td>4.242475</td>\n",
       "      <td>10.770752</td>\n",
       "      <td>4.858503</td>\n",
       "      <td>4.576006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>9.856863</td>\n",
       "      <td>9.850980</td>\n",
       "      <td>1.001961</td>\n",
       "      <td>1.001961</td>\n",
       "      <td>13.556863</td>\n",
       "      <td>11.074510</td>\n",
       "      <td>5.845098</td>\n",
       "      <td>4.831373</td>\n",
       "      <td>11.354902</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>5.336828</td>\n",
       "      <td>10.425229</td>\n",
       "      <td>4.679287</td>\n",
       "      <td>4.365888</td>\n",
       "      <td>10.555834</td>\n",
       "      <td>4.775979</td>\n",
       "      <td>4.483465</td>\n",
       "      <td>10.096011</td>\n",
       "      <td>4.594728</td>\n",
       "      <td>4.282331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>9.030837</td>\n",
       "      <td>10.522026</td>\n",
       "      <td>2.346916</td>\n",
       "      <td>0.484581</td>\n",
       "      <td>14.929515</td>\n",
       "      <td>9.914097</td>\n",
       "      <td>7.429515</td>\n",
       "      <td>4.213656</td>\n",
       "      <td>10.986784</td>\n",
       "      <td>11.856828</td>\n",
       "      <td>...</td>\n",
       "      <td>5.684207</td>\n",
       "      <td>11.149861</td>\n",
       "      <td>5.150235</td>\n",
       "      <td>4.730764</td>\n",
       "      <td>10.955354</td>\n",
       "      <td>5.022493</td>\n",
       "      <td>4.648573</td>\n",
       "      <td>9.707656</td>\n",
       "      <td>4.356117</td>\n",
       "      <td>4.128744</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows Ã— 36 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      HomeTeam   AwayTeam      FTHG      FTAG         HS         AS       HST  \\\n",
       "FTR                                                                             \n",
       "0    10.927944   8.571178  0.602812  2.233743  12.430580  12.776801  4.797891   \n",
       "1     9.856863   9.850980  1.001961  1.001961  13.556863  11.074510  5.845098   \n",
       "2     9.030837  10.522026  2.346916  0.484581  14.929515   9.914097  7.429515   \n",
       "\n",
       "          AST         HF         AF  ...  HHCorners    HAShots  HAShotsTarget  \\\n",
       "FTR                                  ...                                        \n",
       "0    6.126538  11.404218  11.611599  ...   5.069872   9.603560       4.189039   \n",
       "1    4.831373  11.354902  12.000000  ...   5.336828  10.425229       4.679287   \n",
       "2    4.213656  10.986784  11.856828  ...   5.684207  11.149861       5.150235   \n",
       "\n",
       "     HACorners    AHShots  AHShotsTarget  AHCorners    AAShots  AAShotsTarget  \\\n",
       "FTR                                                                             \n",
       "0     4.165731   9.853875       4.291985   4.242475  10.770752       4.858503   \n",
       "1     4.365888  10.555834       4.775979   4.483465  10.096011       4.594728   \n",
       "2     4.730764  10.955354       5.022493   4.648573   9.707656       4.356117   \n",
       "\n",
       "     AACorners  \n",
       "FTR             \n",
       "0     4.576006  \n",
       "1     4.282331  \n",
       "2     4.128744  \n",
       "\n",
       "[3 rows x 36 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.groupby('FTR').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Frequency')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# show plots in the notebook\n",
    "%matplotlib inline\n",
    "\n",
    "# histogram of results\n",
    "dataset[\"FTR\"].hist()\n",
    "plt.title('Histogram of Results')\n",
    "plt.xlabel('Result')\n",
    "plt.ylabel('Frequency')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all the columns from the dataframe.\n",
    "columns = dataset.columns.tolist()\n",
    "# Filter the columns to remove ones we don't want.\n",
    "columns = [c for c in columns if c not in [\"Season\",\"FTHG\", \"FTAG\", \"FTR\", \"HS\", \"AS\", \"HST\", \"HST\", \"AST\", \"HF\", \"AF\", \"HC\", \n",
    "\"AC\", \"HY\", \"AY\", \"HR\", \"AR\", \"AS\"]]\n",
    "\n",
    "# Store the variable we'll be predicting on.\n",
    "target = \"FTR\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1391, 38)\n",
      "(596, 38)\n"
     ]
    }
   ],
   "source": [
    "# Generate the training set.  Set random_state to be able to replicate results. 0.7 to not overfit data.\n",
    "train = dataset.sample(frac=0.7, random_state=1)\n",
    "# Select anything not in the training set and put it in the testing set.\n",
    "test = dataset.loc[~dataset.index.isin(train.index)]\n",
    "# Print the shapes of both sets.\n",
    "print(train.shape)\n",
    "print(test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='warn', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='warn', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize the model class.\n",
    "model = LogisticRegression()\n",
    "# Fit the model to the training data.\n",
    "model.fit(train[columns], train[target])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5262401150251618"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#accuracy\n",
    "model.score(train[columns], train[target])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.233221476510067"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import the scikit-learn function to compute error.\n",
    "from sklearn.metrics import mean_squared_error\n",
    "# Generate our predictions for the test set.\n",
    "predictions = model.predict(test[columns])\n",
    "\n",
    "# Compute error between our test predictions and the actual values.\n",
    "mean_squared_error(predictions, test[target])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.1718188353702372"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#mean\n",
    "train[target].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 2 0 0 2 2 2 2 2 2 0 0 2 2 0 2 2 2 2 2 2 2 1 0 2 0 2 2 2 0 2 0 2 2 2 2 2\n",
      " 2 2 0 2 2 2 2 2 2 2 2 2 2 0 2 0 2 0 0 2 2 0 2 2 2 2 2 0 0 2 0 0 0 0 2 2 0\n",
      " 0 2 2 2 2 2 0 0 2 2 2 0 2 2 0 2 2 2 2 0 0 0 2 2 2 2 2 2 0 0 0 2 2 0 0 0 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 0 2 0 2 0 2 0 2 0 0 2 0 0 2 2 2 2 2 2 0 2 2 2 2 2 0\n",
      " 2 0 2 2 2 0 2 2 2 2 0 2 2 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 2 2 2 2 0\n",
      " 2 0 0 2 0 2 2 2 2 2 0 2 2 0 0 2 2 2 2 2 2 0 2 0 2 2 0 0 0 2 2 2 2 2 0 2 2\n",
      " 2 0 2 2 0 0 0 2 2 2 2 2 2 0 2 0 2 0 2 2 2 0 2 2 2 2 2 2 0 2 2 2 2 2 2 2 2\n",
      " 2 0 2 0 1 2 0 2 2 2 2 2 2 2 2 0 2 2 2 0 2 2 2 2 2 2 2 2 2 0 2 2 2 2 0 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 2 0 2 2 2 2 2 2 0 2 2 2 2 0 2 0 2 2 0 2 2\n",
      " 2 0 2 0 1 2 2 2 2 2 0 2 0 2 2 0 2 2 2 0 0 2 2 0 2 2 2 2 0 2 0 2 2 2 2 0 2\n",
      " 2 2 0 2 0 2 2 0 0 0 2 2 0 2 0 2 2 0 0 2 2 2 0 0 2 0 0 2 2 2 2 2 2 0 0 0 2\n",
      " 0 0 2 2 2 2 0 0 2 2 2 0 0 2 2 2 0 0 0 2 2 2 2 2 2 0 2 0 2 0 0 0 0 2 2 0 2\n",
      " 2 2 2 0 0 2 2 2 2 2 0 2 2 0 2 0 0 2 2 2 2 2 2 0 0 0 0 2 2 2 0 2 2 1 2 2 0\n",
      " 2 0 0 2 2 0 2 0 2 0 0 2 2 2 2 2 2 2 0 2 0 2 2 2 2 2 0 2 2 2 0 0 0 2 2 0 0\n",
      " 0 0 2 2 2 2 2 0 2 2 0 2 2 2 0 0 0 2 0 2 2 2 2 2 0 2 0 0 2 2 0 0 2 2 2 2 0\n",
      " 2 0 2 2 0 2 0 0 2 0 2 2 0 2 2 2 0 2 2 2 1 2 1 0 2 2 2 2 2 2 0 2 2 2 0 2 2\n",
      " 2 2 2 2]\n"
     ]
    }
   ],
   "source": [
    "print(predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.52778334 0.23707172 0.23514494]\n",
      " [0.15807671 0.25797772 0.58394557]\n",
      " [0.44831888 0.30265608 0.24902505]\n",
      " ...\n",
      " [0.08391627 0.18279935 0.73328438]\n",
      " [0.36456658 0.23456329 0.40087013]\n",
      " [0.21032792 0.26331487 0.52635721]]\n"
     ]
    }
   ],
   "source": [
    "# generate class probabilities\n",
    "probs = model.predict_proba(test[columns])\n",
    "print (probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.51428571 0.54285714 0.55       0.46428571 0.43884892 0.53956835\n",
      " 0.53956835 0.51798561 0.50724638 0.45255474]\n",
      "0.5067200915787295\n"
     ]
    }
   ],
   "source": [
    "# evaluate the model using 10-fold cross-validation\n",
    "scores = cross_val_score(LogisticRegression(), train[columns], train[target], scoring='accuracy', cv=10)\n",
    "print (scores)\n",
    "print (scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load test dataset\n",
    "testset = pandas.read_csv('C:/Users/Thoma/OneDrive/Desktop/PredictorFour/TestEPLData.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LabelEncoder()"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Do all the same transformation\n",
    "del testset['ID']\n",
    "del testset['Date']\n",
    "del testset['Referee']\n",
    "del testset['HTHG']\n",
    "del testset['HTAG']\n",
    "del testset['HTR-A']\n",
    "del testset['HTR-D']\n",
    "del testset['HTR-H']\n",
    "del testset['FTHG']\n",
    "del testset['FTAG']\n",
    "del testset['HS']\n",
    "del testset['AS']\n",
    "del testset['HST']\n",
    "del testset['AST']\n",
    "del testset['HF']\n",
    "del testset['AF']\n",
    "del testset['HC']\n",
    "del testset['AC']\n",
    "del testset['HY']\n",
    "del testset['AY']\n",
    "del testset['HR']\n",
    "del testset['AR']\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "testset['HHWins'] = np.where(testset['HHGames'] < 1, testset['HHWins'], testset['HHWins']/testset['HHGames'])\n",
    "testset['AHWins'] = np.where(testset['AHGames'] < 1, testset['AHWins'], testset['AHWins']/testset['AHGames'])\n",
    "testset['HAWins'] = np.where(testset['HAGames'] < 1, testset['HAWins'], testset['HAWins']/testset['HAGames'])\n",
    "testset['AAWins'] = np.where(testset['AAGames'] < 1, testset['AAWins'], testset['AAWins']/testset['AAGames'])\n",
    "lbl_enc = LabelEncoder()\n",
    "lbl_enc.fit(testset.FTR)\n",
    "testset.FTR = lbl_enc.transform(testset.FTR)\n",
    "lbl_enc.fit(testset.HomeTeam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HomeTeam</th>\n",
       "      <th>AwayTeam</th>\n",
       "      <th>FTR</th>\n",
       "      <th>Season</th>\n",
       "      <th>HHGames</th>\n",
       "      <th>HAGames</th>\n",
       "      <th>AAGames</th>\n",
       "      <th>AHGames</th>\n",
       "      <th>HHWins</th>\n",
       "      <th>AHWins</th>\n",
       "      <th>...</th>\n",
       "      <th>HHCorners</th>\n",
       "      <th>HAShots</th>\n",
       "      <th>HAShotsTarget</th>\n",
       "      <th>HACorners</th>\n",
       "      <th>AHShots</th>\n",
       "      <th>AHShotsTarget</th>\n",
       "      <th>AHCorners</th>\n",
       "      <th>AAShots</th>\n",
       "      <th>AAShotsTarget</th>\n",
       "      <th>AACorners</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>2016-2017</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.50</td>\n",
       "      <td>...</td>\n",
       "      <td>10.126185</td>\n",
       "      <td>17.283367</td>\n",
       "      <td>5.469031</td>\n",
       "      <td>8.212262</td>\n",
       "      <td>9.115458</td>\n",
       "      <td>3.210376</td>\n",
       "      <td>3.081837</td>\n",
       "      <td>12.192212</td>\n",
       "      <td>5.394159</td>\n",
       "      <td>4.929675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>2016-2017</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.50</td>\n",
       "      <td>...</td>\n",
       "      <td>5.566333</td>\n",
       "      <td>9.691024</td>\n",
       "      <td>2.447625</td>\n",
       "      <td>4.970323</td>\n",
       "      <td>14.242259</td>\n",
       "      <td>5.998860</td>\n",
       "      <td>3.610158</td>\n",
       "      <td>6.690125</td>\n",
       "      <td>2.872768</td>\n",
       "      <td>5.313723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>2016-2017</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.25</td>\n",
       "      <td>...</td>\n",
       "      <td>7.501354</td>\n",
       "      <td>11.991029</td>\n",
       "      <td>2.612860</td>\n",
       "      <td>7.385992</td>\n",
       "      <td>13.624285</td>\n",
       "      <td>4.635256</td>\n",
       "      <td>8.654320</td>\n",
       "      <td>8.048362</td>\n",
       "      <td>3.461584</td>\n",
       "      <td>2.060494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>2016-2017</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>4.446224</td>\n",
       "      <td>8.282644</td>\n",
       "      <td>2.349026</td>\n",
       "      <td>4.103347</td>\n",
       "      <td>17.548431</td>\n",
       "      <td>2.096058</td>\n",
       "      <td>4.031079</td>\n",
       "      <td>12.970043</td>\n",
       "      <td>3.799455</td>\n",
       "      <td>5.209236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>13</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>2016-2017</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>6.641144</td>\n",
       "      <td>8.345680</td>\n",
       "      <td>4.462204</td>\n",
       "      <td>2.934759</td>\n",
       "      <td>20.026353</td>\n",
       "      <td>7.432527</td>\n",
       "      <td>9.990788</td>\n",
       "      <td>17.261448</td>\n",
       "      <td>4.149488</td>\n",
       "      <td>6.069197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>18</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>2016-2017</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.25</td>\n",
       "      <td>...</td>\n",
       "      <td>4.692164</td>\n",
       "      <td>14.533070</td>\n",
       "      <td>5.222151</td>\n",
       "      <td>5.276757</td>\n",
       "      <td>9.375095</td>\n",
       "      <td>2.658002</td>\n",
       "      <td>5.558000</td>\n",
       "      <td>8.915716</td>\n",
       "      <td>1.515408</td>\n",
       "      <td>3.826328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>2016-2017</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0.75</td>\n",
       "      <td>1.00</td>\n",
       "      <td>...</td>\n",
       "      <td>10.120587</td>\n",
       "      <td>13.838605</td>\n",
       "      <td>5.655460</td>\n",
       "      <td>4.241193</td>\n",
       "      <td>16.563944</td>\n",
       "      <td>6.733074</td>\n",
       "      <td>6.483788</td>\n",
       "      <td>19.096320</td>\n",
       "      <td>7.065241</td>\n",
       "      <td>8.135566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2016-2017</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.40</td>\n",
       "      <td>...</td>\n",
       "      <td>5.823245</td>\n",
       "      <td>17.437872</td>\n",
       "      <td>4.674764</td>\n",
       "      <td>5.223290</td>\n",
       "      <td>10.113379</td>\n",
       "      <td>1.829122</td>\n",
       "      <td>3.414344</td>\n",
       "      <td>6.203114</td>\n",
       "      <td>1.057577</td>\n",
       "      <td>3.536195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>2016-2017</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.50</td>\n",
       "      <td>...</td>\n",
       "      <td>7.685137</td>\n",
       "      <td>19.625089</td>\n",
       "      <td>7.003345</td>\n",
       "      <td>6.294061</td>\n",
       "      <td>8.282382</td>\n",
       "      <td>2.902540</td>\n",
       "      <td>3.946533</td>\n",
       "      <td>9.554056</td>\n",
       "      <td>3.349026</td>\n",
       "      <td>4.221793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>12</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>2016-2017</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.25</td>\n",
       "      <td>...</td>\n",
       "      <td>7.216262</td>\n",
       "      <td>12.414855</td>\n",
       "      <td>5.271132</td>\n",
       "      <td>4.012176</td>\n",
       "      <td>10.293520</td>\n",
       "      <td>2.532171</td>\n",
       "      <td>3.718757</td>\n",
       "      <td>8.158832</td>\n",
       "      <td>1.441738</td>\n",
       "      <td>5.231624</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows Ã— 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   HomeTeam  AwayTeam  FTR     Season  HHGames  HAGames  AAGames  AHGames  \\\n",
       "0         8        15    0  2016-2017        2        5        4        4   \n",
       "1         1        17    0  2016-2017        4        4        4        4   \n",
       "2         4         5    0  2016-2017        4        4        4        4   \n",
       "3        11        19    0  2016-2017        4        4        4        4   \n",
       "4        13        10    0  2016-2017        4        4        3        4   \n",
       "5        18        14    0  2016-2017        4        4        4        4   \n",
       "6         9        16    0  2016-2017        4        4        4        4   \n",
       "7         0         2    0  2016-2017        4        4        3        5   \n",
       "8         3         6    0  2016-2017        4        4        4        4   \n",
       "9        12         7    0  2016-2017        4        4        4        4   \n",
       "\n",
       "   HHWins  AHWins  ...  HHCorners    HAShots  HAShotsTarget  HACorners  \\\n",
       "0    1.00    0.50  ...  10.126185  17.283367       5.469031   8.212262   \n",
       "1    0.75    0.50  ...   5.566333   9.691024       2.447625   4.970323   \n",
       "2    0.25    0.25  ...   7.501354  11.991029       2.612860   7.385992   \n",
       "3    0.00    0.00  ...   4.446224   8.282644       2.349026   4.103347   \n",
       "4    0.25    0.00  ...   6.641144   8.345680       4.462204   2.934759   \n",
       "5    0.25    0.25  ...   4.692164  14.533070       5.222151   5.276757   \n",
       "6    0.75    1.00  ...  10.120587  13.838605       5.655460   4.241193   \n",
       "7    0.75    0.40  ...   5.823245  17.437872       4.674764   5.223290   \n",
       "8    0.75    0.50  ...   7.685137  19.625089       7.003345   6.294061   \n",
       "9    0.50    0.25  ...   7.216262  12.414855       5.271132   4.012176   \n",
       "\n",
       "     AHShots  AHShotsTarget  AHCorners    AAShots  AAShotsTarget  AACorners  \n",
       "0   9.115458       3.210376   3.081837  12.192212       5.394159   4.929675  \n",
       "1  14.242259       5.998860   3.610158   6.690125       2.872768   5.313723  \n",
       "2  13.624285       4.635256   8.654320   8.048362       3.461584   2.060494  \n",
       "3  17.548431       2.096058   4.031079  12.970043       3.799455   5.209236  \n",
       "4  20.026353       7.432527   9.990788  17.261448       4.149488   6.069197  \n",
       "5   9.375095       2.658002   5.558000   8.915716       1.515408   3.826328  \n",
       "6  16.563944       6.733074   6.483788  19.096320       7.065241   8.135566  \n",
       "7  10.113379       1.829122   3.414344   6.203114       1.057577   3.536195  \n",
       "8   8.282382       2.902540   3.946533   9.554056       3.349026   4.221793  \n",
       "9  10.293520       2.532171   3.718757   8.158832       1.441738   5.231624  \n",
       "\n",
       "[10 rows x 24 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['HomeTeam', 'AwayTeam', 'FTR', 'Season', 'HHGames', 'HAGames',\n",
       "       'AAGames', 'AHGames', 'HHWins', 'AHWins', 'AAWins', 'HAWins', 'HHShots',\n",
       "       'HHShotsTarget', 'HHCorners', 'HAShots', 'HAShotsTarget', 'HACorners',\n",
       "       'AHShots', 'AHShotsTarget', 'AHCorners', 'AAShots', 'AAShotsTarget',\n",
       "       'AACorners'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testset.columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all the columns from the dataframe.\n",
    "columns2 = testset.columns.tolist()\n",
    "# Filter the columns to remove ones we don't want.\n",
    "columns2 = [c for c in columns if c not in [\"Season\"]]\n",
    "\n",
    "# Store the variable we'll be predicting on.\n",
    "target2 = \"FTR\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate our predictions for the test set.\n",
    "predictions2 = model.predict(testset[columns2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 2, 2, 0, 0, 2, 2, 2, 2, 2])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
